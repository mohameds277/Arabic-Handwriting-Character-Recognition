{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 7500733,
          "sourceType": "datasetVersion",
          "datasetId": 4367760
        }
      ],
      "dockerImageVersionId": 30635,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohameds277/Arabic-Handwriting-Character-Recognition/blob/main/Base_model_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch import Tensor\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "train_path = '/kaggle/input/arabic-data-set/train/train/'\n",
        "test_path = '/kaggle/input/arabic-data-set/test/test/'\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # Store the filenames and labels\n",
        "        self.image_filenames = []\n",
        "        self.labels = []\n",
        "        for filename in os.listdir(data_dir):\n",
        "            if filename.endswith('.png'):\n",
        "                label = int(filename.split('_')[-1].split('.')[0]) - 1\n",
        "                self.image_filenames.append(filename)\n",
        "                self.labels.append(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_filenames[idx]\n",
        "        label = self.labels[idx]\n",
        "        img_path = os.path.join(self.data_dir, img_name)\n",
        "        img = Image.open(img_path).convert('L')  # Convert to grayscale\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_image_dataset = CustomImageDataset(train_path, transform=transform)\n",
        "test_dataset = CustomImageDataset(test_path, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size= 64, shuffle=False)\n",
        "loader = DataLoader(train_image_dataset, batch_size= 64, shuffle=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-01-30T15:17:59.628994Z",
          "iopub.execute_input": "2024-01-30T15:17:59.629831Z",
          "iopub.status.idle": "2024-01-30T15:17:59.681541Z",
          "shell.execute_reply.started": "2024-01-30T15:17:59.629798Z",
          "shell.execute_reply": "2024-01-30T15:17:59.680538Z"
        },
        "trusted": true,
        "id": "1BMe1XrUWiC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvolutionNNetwork(nn.Module):\n",
        "    def __init__(self, output_channels, kernel_size, dropout_rate,learning_rate,padding):\n",
        "        super(ConvolutionNNetwork, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, output_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(output_channels, 2 * output_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(2 * output_channels, 2 * output_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.drop_out = nn.Dropout(dropout_rate)\n",
        "        self.fc1 = nn.Linear(2 * 2 * (2 * output_channels) * 4, 1000)\n",
        "        self.fc2 = nn.Linear(1000, 28)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.drop_out(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-30T15:17:59.683304Z",
          "iopub.execute_input": "2024-01-30T15:17:59.683645Z",
          "iopub.status.idle": "2024-01-30T15:17:59.695188Z",
          "shell.execute_reply.started": "2024-01-30T15:17:59.683615Z",
          "shell.execute_reply": "2024-01-30T15:17:59.693971Z"
        },
        "trusted": true,
        "id": "wC1MQKZxWiC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(model, train_loader, valid_loader, criterion, optimizer, num_epochs=15):\n",
        "    val_loss_list = []\n",
        "    current_patience = 0\n",
        "    patience=3\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for i, data in enumerate(loader):\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)  # Move data to GPU\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            valid_predictions = []\n",
        "            valid_labels = []\n",
        "            val_loss = 0.0\n",
        "            for inputs, labels in valid_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                valid_predictions.extend(predicted.cpu().numpy())\n",
        "                valid_labels.extend(labels.cpu().numpy())\n",
        "                val_loss += criterion(outputs, labels).item()\n",
        "\n",
        "            val_loss /= len(valid_loader)\n",
        "            val_loss_list.append(val_loss)\n",
        "\n",
        "            accuracy = accuracy_score(valid_labels, valid_predictions)\n",
        "            print(f'Epoch {epoch + 1}/{num_epochs}, Validation Accuracy: {accuracy:.4f}')\n",
        "\n",
        "        if epoch > 0 and val_loss < val_loss_list[epoch - 1]:\n",
        "            current_patience = 0\n",
        "        else:\n",
        "            current_patience += 1\n",
        "\n",
        "        if current_patience >= patience:\n",
        "            print(f'Early stopping at epoch {epoch + 1}')\n",
        "            break\n",
        "\n",
        "        print(f'   Val loss = ',{val_loss})\n",
        "    return accuracy\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-30T15:17:59.696633Z",
          "iopub.execute_input": "2024-01-30T15:17:59.696996Z",
          "iopub.status.idle": "2024-01-30T15:17:59.710397Z",
          "shell.execute_reply.started": "2024-01-30T15:17:59.696948Z",
          "shell.execute_reply": "2024-01-30T15:17:59.709190Z"
        },
        "trusted": true,
        "id": "Qquc7YdWWiC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.model_selection import ParameterGrid, train_test_split\n",
        "\n",
        "param_grid = {\n",
        "    'output_channels': [32, 64],\n",
        "    'kernel_size': [3, 5],\n",
        "    'dropout_rate': [0.2, 0.5],\n",
        "    'learning_rate':[0.001,0.0001]\n",
        "}\n",
        "\n",
        "param_combinations = list(ParameterGrid(param_grid))\n",
        "\n",
        "best_accuracy = 0.0\n",
        "best_hyperparameters = {}\n",
        "\n",
        "\n",
        "\n",
        "for params in param_combinations:\n",
        "\n",
        "    if params['kernel_size'] == 3:\n",
        "        params['padding'] = 1\n",
        "    elif params['kernel_size'] == 5:\n",
        "        params['padding'] = 2\n",
        "\n",
        "    model = ConvolutionNNetwork(**params).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=params['learning_rate'],weight_decay=1e-5)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    print(f\"\\nTraining model with hyperparameters: {params}\")\n",
        "    accuracy=train_and_evaluate(model, loader, test_loader, criterion, optimizer)\n",
        "\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_hyperparameters = params.copy()\n",
        "\n",
        "print(f'\\nBest Test Accuracy: {best_accuracy:.4f} with hyperparameters: {best_hyperparameters}')\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-30T15:17:59.712494Z",
          "iopub.execute_input": "2024-01-30T15:17:59.712862Z",
          "iopub.status.idle": "2024-01-30T16:26:00.348422Z",
          "shell.execute_reply.started": "2024-01-30T15:17:59.712833Z",
          "shell.execute_reply": "2024-01-30T16:26:00.347199Z"
        },
        "trusted": true,
        "id": "1wf7824RWiC-",
        "outputId": "51ba4619-efdf-4f8c-b9a5-84db0de1524c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "\nTraining model with hyperparameters: {'dropout_rate': 0.2, 'kernel_size': 3, 'learning_rate': 0.001, 'output_channels': 32, 'padding': 1}\nEpoch 1/15, Validation Accuracy: 0.7560\n   Val loss =  {0.7413518406310171}\nEpoch 2/15, Validation Accuracy: 0.8557\n   Val loss =  {0.45389031520429646}\nEpoch 3/15, Validation Accuracy: 0.8673\n   Val loss =  {0.41917518962104366}\nEpoch 4/15, Validation Accuracy: 0.9009\n   Val loss =  {0.3233347627914177}\nEpoch 5/15, Validation Accuracy: 0.9060\n   Val loss =  {0.29896158134599904}\nEpoch 6/15, Validation Accuracy: 0.9101\n   Val loss =  {0.2980285994005653}\nEpoch 7/15, Validation Accuracy: 0.9152\n   Val loss =  {0.26945700468319767}\nEpoch 8/15, Validation Accuracy: 0.9116\n   Val loss =  {0.290233110762992}\nEpoch 9/15, Validation Accuracy: 0.9208\n   Val loss =  {0.26231945868370665}\nEpoch 10/15, Validation Accuracy: 0.9253\n   Val loss =  {0.25556695264465407}\nEpoch 11/15, Validation Accuracy: 0.9137\n   Val loss =  {0.2825080874674725}\nEpoch 12/15, Validation Accuracy: 0.9277\n   Val loss =  {0.24826422470779913}\nEpoch 13/15, Validation Accuracy: 0.9256\n   Val loss =  {0.2912435863377913}\nEpoch 14/15, Validation Accuracy: 0.9232\n   Val loss =  {0.28628306484447336}\nEpoch 15/15, Validation Accuracy: 0.9318\n   Val loss =  {0.27202687291252725}\n\nTraining model with hyperparameters: {'dropout_rate': 0.2, 'kernel_size': 3, 'learning_rate': 0.001, 'output_channels': 64, 'padding': 1}\nEpoch 1/15, Validation Accuracy: 0.7702\n   Val loss =  {0.6767431025235158}\nEpoch 2/15, Validation Accuracy: 0.8610\n   Val loss =  {0.4470172580683006}\nEpoch 3/15, Validation Accuracy: 0.8896\n   Val loss =  {0.34769013664632475}\nEpoch 4/15, Validation Accuracy: 0.9113\n   Val loss =  {0.2854176290192694}\nEpoch 5/15, Validation Accuracy: 0.9146\n   Val loss =  {0.28028135310928776}\nEpoch 6/15, Validation Accuracy: 0.9265\n   Val loss =  {0.2406292143014242}\nEpoch 7/15, Validation Accuracy: 0.9048\n   Val loss =  {0.31603556829241086}\nEpoch 8/15, Validation Accuracy: 0.9098\n   Val loss =  {0.31850677742710654}\nEpoch 9/15, Validation Accuracy: 0.9280\n   Val loss =  {0.2515167495552099}\nEpoch 10/15, Validation Accuracy: 0.9437\n   Val loss =  {0.214823399090542}\nEpoch 11/15, Validation Accuracy: 0.9262\n   Val loss =  {0.2760394253539589}\nEpoch 12/15, Validation Accuracy: 0.9310\n   Val loss =  {0.26322334498729344}\nEpoch 13/15, Validation Accuracy: 0.9241\n   Val loss =  {0.2726242812174671}\nEpoch 14/15, Validation Accuracy: 0.9324\n   Val loss =  {0.2521567178784676}\nEpoch 15/15, Validation Accuracy: 0.9259\n   Val loss =  {0.28765596976538876}\n\nTraining model with hyperparameters: {'dropout_rate': 0.2, 'kernel_size': 3, 'learning_rate': 0.0001, 'output_channels': 32, 'padding': 1}\nEpoch 1/15, Validation Accuracy: 0.4387\n   Val loss =  {1.870281437657914}\nEpoch 2/15, Validation Accuracy: 0.5390\n   Val loss =  {1.4627854981512394}\nEpoch 3/15, Validation Accuracy: 0.6479\n   Val loss =  {1.1472554611709882}\nEpoch 4/15, Validation Accuracy: 0.6976\n   Val loss =  {0.9618495815205124}\nEpoch 5/15, Validation Accuracy: 0.7390\n   Val loss =  {0.8358317613601685}\nEpoch 6/15, Validation Accuracy: 0.7667\n   Val loss =  {0.7453291331822017}\nEpoch 7/15, Validation Accuracy: 0.7881\n   Val loss =  {0.6769482965739269}\nEpoch 8/15, Validation Accuracy: 0.8030\n   Val loss =  {0.6312077242248463}\nEpoch 9/15, Validation Accuracy: 0.8086\n   Val loss =  {0.6101844738114555}\nEpoch 10/15, Validation Accuracy: 0.8321\n   Val loss =  {0.5582200991657545}\nEpoch 11/15, Validation Accuracy: 0.8271\n   Val loss =  {0.5476841971559344}\nEpoch 12/15, Validation Accuracy: 0.8476\n   Val loss =  {0.5101951135779327}\nEpoch 13/15, Validation Accuracy: 0.8491\n   Val loss =  {0.48548076737601803}\nEpoch 14/15, Validation Accuracy: 0.8580\n   Val loss =  {0.4818979692908953}\nEpoch 15/15, Validation Accuracy: 0.8625\n   Val loss =  {0.4600037347595647}\n\nTraining model with hyperparameters: {'dropout_rate': 0.2, 'kernel_size': 3, 'learning_rate': 0.0001, 'output_channels': 64, 'padding': 1}\nEpoch 1/15, Validation Accuracy: 0.5006\n   Val loss =  {1.6372045368518469}\nEpoch 2/15, Validation Accuracy: 0.6589\n   Val loss =  {1.0964409540284354}\nEpoch 3/15, Validation Accuracy: 0.7205\n   Val loss =  {0.8516756656034937}\nEpoch 4/15, Validation Accuracy: 0.7696\n   Val loss =  {0.7034054848383058}\nEpoch 5/15, Validation Accuracy: 0.8283\n   Val loss =  {0.5694652941991698}\nEpoch 6/15, Validation Accuracy: 0.8381\n   Val loss =  {0.5264746423037547}\nEpoch 7/15, Validation Accuracy: 0.8527\n   Val loss =  {0.47736660883111776}\nEpoch 8/15, Validation Accuracy: 0.8637\n   Val loss =  {0.4440573642276368}\nEpoch 9/15, Validation Accuracy: 0.8762\n   Val loss =  {0.4033439468662694}\nEpoch 10/15, Validation Accuracy: 0.8818\n   Val loss =  {0.3742408907076098}\nEpoch 11/15, Validation Accuracy: 0.8887\n   Val loss =  {0.3619968407558945}\nEpoch 12/15, Validation Accuracy: 0.8943\n   Val loss =  {0.35457663884702717}\nEpoch 13/15, Validation Accuracy: 0.8958\n   Val loss =  {0.33695490264667655}\nEpoch 14/15, Validation Accuracy: 0.9009\n   Val loss =  {0.3271829587108684}\nEpoch 15/15, Validation Accuracy: 0.9054\n   Val loss =  {0.3104138138159266}\n\nTraining model with hyperparameters: {'dropout_rate': 0.2, 'kernel_size': 5, 'learning_rate': 0.001, 'output_channels': 32, 'padding': 2}\nEpoch 1/15, Validation Accuracy: 0.7676\n   Val loss =  {0.6876436539416043}\nEpoch 2/15, Validation Accuracy: 0.8432\n   Val loss =  {0.49797540340783464}\nEpoch 3/15, Validation Accuracy: 0.8807\n   Val loss =  {0.36791192473105666}\nEpoch 4/15, Validation Accuracy: 0.9054\n   Val loss =  {0.306109164121016}\nEpoch 5/15, Validation Accuracy: 0.9012\n   Val loss =  {0.333736038432931}\nEpoch 6/15, Validation Accuracy: 0.9170\n   Val loss =  {0.27244201232239884}\nEpoch 7/15, Validation Accuracy: 0.9283\n   Val loss =  {0.24156201701119262}\nEpoch 8/15, Validation Accuracy: 0.9196\n   Val loss =  {0.25329219816990617}\nEpoch 9/15, Validation Accuracy: 0.9241\n   Val loss =  {0.251951683382943}\nEpoch 10/15, Validation Accuracy: 0.9202\n   Val loss =  {0.26865944624790605}\nEpoch 11/15, Validation Accuracy: 0.9241\n   Val loss =  {0.2561468593073341}\nEpoch 12/15, Validation Accuracy: 0.9304\n   Val loss =  {0.2358677238928822}\nEpoch 13/15, Validation Accuracy: 0.9295\n   Val loss =  {0.26921769294817494}\nEpoch 14/15, Validation Accuracy: 0.9366\n   Val loss =  {0.23813068582061328}\nEpoch 15/15, Validation Accuracy: 0.9301\n   Val loss =  {0.26628259333940046}\n\nTraining model with hyperparameters: {'dropout_rate': 0.2, 'kernel_size': 5, 'learning_rate': 0.001, 'output_channels': 64, 'padding': 2}\nEpoch 1/15, Validation Accuracy: 0.7961\n   Val loss =  {0.6270016161900647}\nEpoch 2/15, Validation Accuracy: 0.8583\n   Val loss =  {0.43009171817662584}\nEpoch 3/15, Validation Accuracy: 0.8949\n   Val loss =  {0.3295893379539814}\nEpoch 4/15, Validation Accuracy: 0.9185\n   Val loss =  {0.26823497704177535}\nEpoch 5/15, Validation Accuracy: 0.9304\n   Val loss =  {0.23480893341156672}\nEpoch 6/15, Validation Accuracy: 0.9345\n   Val loss =  {0.22778461128473282}\nEpoch 7/15, Validation Accuracy: 0.9280\n   Val loss =  {0.2353340967927339}\nEpoch 8/15, Validation Accuracy: 0.9330\n   Val loss =  {0.2500869702055769}\nEpoch 9/15, Validation Accuracy: 0.9265\nEarly stopping at epoch 9\n\nTraining model with hyperparameters: {'dropout_rate': 0.2, 'kernel_size': 5, 'learning_rate': 0.0001, 'output_channels': 32, 'padding': 2}\nEpoch 1/15, Validation Accuracy: 0.5152\n   Val loss =  {1.5769593760652363}\nEpoch 2/15, Validation Accuracy: 0.6744\n   Val loss =  {1.014038991253331}\nEpoch 3/15, Validation Accuracy: 0.7408\n   Val loss =  {0.8061427923868287}\nEpoch 4/15, Validation Accuracy: 0.7789\n   Val loss =  {0.6952733903560998}\nEpoch 5/15, Validation Accuracy: 0.7839\n   Val loss =  {0.6607146707345855}\nEpoch 6/15, Validation Accuracy: 0.8122\n   Val loss =  {0.5675949116922775}\nEpoch 7/15, Validation Accuracy: 0.8280\n   Val loss =  {0.5331081877339561}\nEpoch 8/15, Validation Accuracy: 0.8348\n   Val loss =  {0.5224219616853966}\nEpoch 9/15, Validation Accuracy: 0.8491\n   Val loss =  {0.47690278123009877}\nEpoch 10/15, Validation Accuracy: 0.8446\n   Val loss =  {0.4755873401772301}\nEpoch 11/15, Validation Accuracy: 0.8503\n   Val loss =  {0.48161128275799303}\nEpoch 12/15, Validation Accuracy: 0.8536\n   Val loss =  {0.45629314319142755}\nEpoch 13/15, Validation Accuracy: 0.8670\n   Val loss =  {0.420725183948031}\nEpoch 14/15, Validation Accuracy: 0.8705\n   Val loss =  {0.40696589423800417}\nEpoch 15/15, Validation Accuracy: 0.8744\n   Val loss =  {0.3963966344325048}\n\nTraining model with hyperparameters: {'dropout_rate': 0.2, 'kernel_size': 5, 'learning_rate': 0.0001, 'output_channels': 64, 'padding': 2}\nEpoch 1/15, Validation Accuracy: 0.6244\n   Val loss =  {1.183777594341422}\nEpoch 2/15, Validation Accuracy: 0.7393\n   Val loss =  {0.7797880183975652}\nEpoch 3/15, Validation Accuracy: 0.8012\n   Val loss =  {0.6024371498035934}\nEpoch 4/15, Validation Accuracy: 0.8250\n   Val loss =  {0.5390506319279941}\nEpoch 5/15, Validation Accuracy: 0.8491\n   Val loss =  {0.49730833408967506}\nEpoch 6/15, Validation Accuracy: 0.8414\n   Val loss =  {0.4944757029133023}\nEpoch 7/15, Validation Accuracy: 0.8518\n   Val loss =  {0.45323886117845213}\nEpoch 8/15, Validation Accuracy: 0.8679\n   Val loss =  {0.4175001658358664}\nEpoch 9/15, Validation Accuracy: 0.8786\n   Val loss =  {0.38173825279721674}\nEpoch 10/15, Validation Accuracy: 0.8935\n   Val loss =  {0.3498090499976896}\nEpoch 11/15, Validation Accuracy: 0.8872\n   Val loss =  {0.36996469351480593}\nEpoch 12/15, Validation Accuracy: 0.8955\n   Val loss =  {0.3244115749620042}\nEpoch 13/15, Validation Accuracy: 0.9045\n   Val loss =  {0.32310393283951955}\nEpoch 14/15, Validation Accuracy: 0.9051\n   Val loss =  {0.3249318671395194}\nEpoch 15/15, Validation Accuracy: 0.9027\n   Val loss =  {0.309782752591484}\n\nTraining model with hyperparameters: {'dropout_rate': 0.5, 'kernel_size': 3, 'learning_rate': 0.001, 'output_channels': 32, 'padding': 1}\nEpoch 1/15, Validation Accuracy: 0.7179\n   Val loss =  {0.8460110133548953}\nEpoch 2/15, Validation Accuracy: 0.8074\n   Val loss =  {0.5722618384181328}\nEpoch 3/15, Validation Accuracy: 0.8619\n   Val loss =  {0.4519181937541602}\nEpoch 4/15, Validation Accuracy: 0.8723\n   Val loss =  {0.39968762870104807}\nEpoch 5/15, Validation Accuracy: 0.8890\n   Val loss =  {0.33266079903773543}\nEpoch 6/15, Validation Accuracy: 0.9060\n   Val loss =  {0.28718131696278193}\nEpoch 7/15, Validation Accuracy: 0.9113\n   Val loss =  {0.28508283816418556}\nEpoch 8/15, Validation Accuracy: 0.9125\n   Val loss =  {0.2744686742717365}\nEpoch 9/15, Validation Accuracy: 0.9280\n   Val loss =  {0.22837660967741372}\nEpoch 10/15, Validation Accuracy: 0.9211\n   Val loss =  {0.25562469197331733}\nEpoch 11/15, Validation Accuracy: 0.9268\n   Val loss =  {0.2386668727926488}\nEpoch 12/15, Validation Accuracy: 0.9333\n   Val loss =  {0.22076464866129858}\nEpoch 13/15, Validation Accuracy: 0.9345\n   Val loss =  {0.21526257749998345}\nEpoch 14/15, Validation Accuracy: 0.9295\n   Val loss =  {0.22312952880308312}\nEpoch 15/15, Validation Accuracy: 0.9393\n   Val loss =  {0.21005000666065035}\n\nTraining model with hyperparameters: {'dropout_rate': 0.5, 'kernel_size': 3, 'learning_rate': 0.001, 'output_channels': 64, 'padding': 1}\nEpoch 1/15, Validation Accuracy: 0.7658\n   Val loss =  {0.7235678760510571}\nEpoch 2/15, Validation Accuracy: 0.8619\n   Val loss =  {0.436405656191538}\nEpoch 3/15, Validation Accuracy: 0.8658\n   Val loss =  {0.40831573532437376}\nEpoch 4/15, Validation Accuracy: 0.9057\n   Val loss =  {0.3042811357750083}\nEpoch 5/15, Validation Accuracy: 0.9048\n   Val loss =  {0.3010692961935727}\nEpoch 6/15, Validation Accuracy: 0.9280\n   Val loss =  {0.2414633001921312}\nEpoch 7/15, Validation Accuracy: 0.9330\n   Val loss =  {0.22772967379610493}\nEpoch 8/15, Validation Accuracy: 0.9411\n   Val loss =  {0.20451796307878675}\nEpoch 9/15, Validation Accuracy: 0.9196\n   Val loss =  {0.259895329205495}\nEpoch 10/15, Validation Accuracy: 0.9381\n   Val loss =  {0.21368382259641053}\nEpoch 11/15, Validation Accuracy: 0.9390\n   Val loss =  {0.1995135412182448}\nEpoch 12/15, Validation Accuracy: 0.9387\n   Val loss =  {0.20768356330271037}\nEpoch 13/15, Validation Accuracy: 0.9360\n   Val loss =  {0.21577928362871115}\nEpoch 14/15, Validation Accuracy: 0.9414\n   Val loss =  {0.20866366974868863}\nEpoch 15/15, Validation Accuracy: 0.9360\n   Val loss =  {0.21398156185476286}\n\nTraining model with hyperparameters: {'dropout_rate': 0.5, 'kernel_size': 3, 'learning_rate': 0.0001, 'output_channels': 32, 'padding': 1}\nEpoch 1/15, Validation Accuracy: 0.4074\n   Val loss =  {1.9793788442071878}\nEpoch 2/15, Validation Accuracy: 0.5583\n   Val loss =  {1.5011376569855888}\nEpoch 3/15, Validation Accuracy: 0.6381\n   Val loss =  {1.2029902417704743}\nEpoch 4/15, Validation Accuracy: 0.7033\n   Val loss =  {0.977767934214394}\nEpoch 5/15, Validation Accuracy: 0.7488\n   Val loss =  {0.855691817571532}\nEpoch 6/15, Validation Accuracy: 0.7693\n   Val loss =  {0.7560048598163532}\nEpoch 7/15, Validation Accuracy: 0.7875\n   Val loss =  {0.6909569434399875}\nEpoch 8/15, Validation Accuracy: 0.8128\n   Val loss =  {0.6326042869181003}\nEpoch 9/15, Validation Accuracy: 0.8223\n   Val loss =  {0.6023229681095987}\nEpoch 10/15, Validation Accuracy: 0.8345\n   Val loss =  {0.5675263298007677}\nEpoch 11/15, Validation Accuracy: 0.8315\n   Val loss =  {0.54474427790012}\nEpoch 12/15, Validation Accuracy: 0.8497\n   Val loss =  {0.5105766530306834}\nEpoch 13/15, Validation Accuracy: 0.8515\n   Val loss =  {0.4941730173128956}\nEpoch 14/15, Validation Accuracy: 0.8518\n   Val loss =  {0.49120749786215007}\nEpoch 15/15, Validation Accuracy: 0.8649\n   Val loss =  {0.4537938838859774}\n\nTraining model with hyperparameters: {'dropout_rate': 0.5, 'kernel_size': 3, 'learning_rate': 0.0001, 'output_channels': 64, 'padding': 1}\nEpoch 1/15, Validation Accuracy: 0.5327\n   Val loss =  {1.6047146072927512}\nEpoch 2/15, Validation Accuracy: 0.6899\n   Val loss =  {1.0398798449984137}\nEpoch 3/15, Validation Accuracy: 0.7586\n   Val loss =  {0.7955566037375972}\nEpoch 4/15, Validation Accuracy: 0.7854\n   Val loss =  {0.6724355113956163}\nEpoch 5/15, Validation Accuracy: 0.8193\n   Val loss =  {0.589428795958465}\nEpoch 6/15, Validation Accuracy: 0.8357\n   Val loss =  {0.533436083568717}\nEpoch 7/15, Validation Accuracy: 0.8491\n   Val loss =  {0.5009565606432141}\nEpoch 8/15, Validation Accuracy: 0.8524\n   Val loss =  {0.4625559612265173}\nEpoch 9/15, Validation Accuracy: 0.8577\n   Val loss =  {0.45616859956732336}\nEpoch 10/15, Validation Accuracy: 0.8807\n   Val loss =  {0.40891894332642825}\nEpoch 11/15, Validation Accuracy: 0.8756\n   Val loss =  {0.39700705009811327}\nEpoch 12/15, Validation Accuracy: 0.8854\n   Val loss =  {0.3712924246518117}\nEpoch 13/15, Validation Accuracy: 0.8896\n   Val loss =  {0.35586637061721876}\nEpoch 14/15, Validation Accuracy: 0.8911\n   Val loss =  {0.3406344624060505}\nEpoch 15/15, Validation Accuracy: 0.8961\n   Val loss =  {0.33357493242002884}\n\nTraining model with hyperparameters: {'dropout_rate': 0.5, 'kernel_size': 5, 'learning_rate': 0.001, 'output_channels': 32, 'padding': 2}\nEpoch 1/15, Validation Accuracy: 0.7804\n   Val loss =  {0.6513231362936631}\nEpoch 2/15, Validation Accuracy: 0.8256\n   Val loss =  {0.5147140425331188}\nEpoch 3/15, Validation Accuracy: 0.8973\n   Val loss =  {0.32608875576055274}\nEpoch 4/15, Validation Accuracy: 0.9095\n   Val loss =  {0.2767853093034816}\nEpoch 5/15, Validation Accuracy: 0.9134\n   Val loss =  {0.2736608350895486}\nEpoch 6/15, Validation Accuracy: 0.9173\n   Val loss =  {0.25226668929154017}\nEpoch 7/15, Validation Accuracy: 0.9307\n   Val loss =  {0.21843466992085836}\nEpoch 8/15, Validation Accuracy: 0.9357\n   Val loss =  {0.20602112530537373}\nEpoch 9/15, Validation Accuracy: 0.9390\n   Val loss =  {0.2029773082654431}\nEpoch 10/15, Validation Accuracy: 0.9378\n   Val loss =  {0.20165462496708025}\nEpoch 11/15, Validation Accuracy: 0.9420\n   Val loss =  {0.1887340470445606}\nEpoch 12/15, Validation Accuracy: 0.9458\n   Val loss =  {0.19236157525260494}\nEpoch 13/15, Validation Accuracy: 0.9426\n   Val loss =  {0.19395705860740733}\nEpoch 14/15, Validation Accuracy: 0.9476\n   Val loss =  {0.18361653134507952}\nEpoch 15/15, Validation Accuracy: 0.9485\n   Val loss =  {0.17274485944928425}\n\nTraining model with hyperparameters: {'dropout_rate': 0.5, 'kernel_size': 5, 'learning_rate': 0.001, 'output_channels': 64, 'padding': 2}\nEpoch 1/15, Validation Accuracy: 0.7783\n   Val loss =  {0.6744691341553094}\nEpoch 2/15, Validation Accuracy: 0.8417\n   Val loss =  {0.4987567421400322}\nEpoch 3/15, Validation Accuracy: 0.8967\n   Val loss =  {0.3223203973106618}\nEpoch 4/15, Validation Accuracy: 0.9283\n   Val loss =  {0.23923976114898357}\nEpoch 5/15, Validation Accuracy: 0.9092\n   Val loss =  {0.28527572230910353}\nEpoch 6/15, Validation Accuracy: 0.9185\n   Val loss =  {0.25827706675484496}\nEpoch 7/15, Validation Accuracy: 0.9318\n   Val loss =  {0.21505714292233846}\nEpoch 8/15, Validation Accuracy: 0.9357\n   Val loss =  {0.21803434347769}\nEpoch 9/15, Validation Accuracy: 0.9366\n   Val loss =  {0.19483455607913575}\nEpoch 10/15, Validation Accuracy: 0.9449\n   Val loss =  {0.1920100090287204}\nEpoch 11/15, Validation Accuracy: 0.9443\n   Val loss =  {0.20630569959867676}\nEpoch 12/15, Validation Accuracy: 0.9449\n   Val loss =  {0.2144539795886233}\nEpoch 13/15, Validation Accuracy: 0.9384\nEarly stopping at epoch 13\n\nTraining model with hyperparameters: {'dropout_rate': 0.5, 'kernel_size': 5, 'learning_rate': 0.0001, 'output_channels': 32, 'padding': 2}\nEpoch 1/15, Validation Accuracy: 0.5113\n   Val loss =  {1.6483367276641558}\nEpoch 2/15, Validation Accuracy: 0.6571\n   Val loss =  {1.0838721045907938}\nEpoch 3/15, Validation Accuracy: 0.7274\n   Val loss =  {0.8911433860940753}\nEpoch 4/15, Validation Accuracy: 0.7625\n   Val loss =  {0.7272076561765851}\nEpoch 5/15, Validation Accuracy: 0.7935\n   Val loss =  {0.6523794025745032}\nEpoch 6/15, Validation Accuracy: 0.8063\n   Val loss =  {0.6142437047553513}\nEpoch 7/15, Validation Accuracy: 0.8247\n   Val loss =  {0.5535073252219074}\nEpoch 8/15, Validation Accuracy: 0.8310\n   Val loss =  {0.5388930563656789}\nEpoch 9/15, Validation Accuracy: 0.8366\n   Val loss =  {0.5162412872854268}\nEpoch 10/15, Validation Accuracy: 0.8360\n   Val loss =  {0.5093176173713972}\nEpoch 11/15, Validation Accuracy: 0.8527\n   Val loss =  {0.46987770244760335}\nEpoch 12/15, Validation Accuracy: 0.8601\n   Val loss =  {0.44641313069271593}\nEpoch 13/15, Validation Accuracy: 0.8568\n   Val loss =  {0.4573812301991121}\nEpoch 14/15, Validation Accuracy: 0.8786\n   Val loss =  {0.4122436527373656}\nEpoch 15/15, Validation Accuracy: 0.8518\n   Val loss =  {0.44735436338298723}\n\nTraining model with hyperparameters: {'dropout_rate': 0.5, 'kernel_size': 5, 'learning_rate': 0.0001, 'output_channels': 64, 'padding': 2}\nEpoch 1/15, Validation Accuracy: 0.5917\n   Val loss =  {1.2702221263129756}\nEpoch 2/15, Validation Accuracy: 0.7455\n   Val loss =  {0.7929161157248155}\nEpoch 3/15, Validation Accuracy: 0.8006\n   Val loss =  {0.6257294590743083}\nEpoch 4/15, Validation Accuracy: 0.8256\n   Val loss =  {0.5458702979222784}\nEpoch 5/15, Validation Accuracy: 0.8423\n   Val loss =  {0.5025867274347341}\nEpoch 6/15, Validation Accuracy: 0.8512\n   Val loss =  {0.4815949730153354}\nEpoch 7/15, Validation Accuracy: 0.8595\n   Val loss =  {0.4391887873973487}\nEpoch 8/15, Validation Accuracy: 0.8789\n   Val loss =  {0.3940635253235979}\nEpoch 9/15, Validation Accuracy: 0.8890\n   Val loss =  {0.3662906103539017}\nEpoch 10/15, Validation Accuracy: 0.8896\n   Val loss =  {0.35685747299554216}\nEpoch 11/15, Validation Accuracy: 0.8935\n   Val loss =  {0.339132269879557}\nEpoch 12/15, Validation Accuracy: 0.8985\n   Val loss =  {0.32576300513069584}\nEpoch 13/15, Validation Accuracy: 0.8929\n   Val loss =  {0.33437469545400367}\nEpoch 14/15, Validation Accuracy: 0.9077\n   Val loss =  {0.3016390215675786}\nEpoch 15/15, Validation Accuracy: 0.9110\n   Val loss =  {0.28704041636215066}\n\nBest Test Accuracy: 0.9485 with hyperparameters: {'dropout_rate': 0.5, 'kernel_size': 5, 'learning_rate': 0.001, 'output_channels': 32, 'padding': 2}\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}